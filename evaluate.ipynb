{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = str(os.getenv(\"LANGCHAIN_API_KEY\"))\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\" # Update with your API URL if using a hosted instance of Langsmith.\n",
    "project_name = \"2.pdf_chat_router_issue_assistant\" # Update with your project name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have some hard-coded examples here.\n",
    "examples = [\n",
    "(\"What is the name of the company that provides the 'Sparsh' policies?\", \"The name of the company that provides the 'Sparsh' policies is Infosys Limited.\"),\n",
    "(\"What types of agreements must be signed upon employment with Infosys Limited?\", \"Upon employment with Infosys Limited, one must sign certain mandatory agreements, including but not limited to the Confidentiality, Intellectual Property Rights, the Code of Business Conduct and Ethics.\"),\n",
    "(\"What type of information is considered confidential at Infosys Limited?\", \"At Infosys Limited, confidential information includes but is not limited to current and future business information of the Company, its clients, suppliers, or employees.\"),\n",
    "(\"What is the role of the individual in this executive employment contract?\", \"The role of the individual in this executive employment contract is Chief Operating Officer of Infosys Limited.\"),\n",
    "(\"Where is the work location of the individual in this executive employment contract?\", \"The work location of the individual in this executive employment contract is Bangalore, India.\"),\n",
    "(\"What is the definition of 'affiliate' in this executive employment contract?\", \"In this executive employment contract, 'affiliate' means any entity that controls, is controlled by, or is under common control with the Company. For purposes of this Agreement, 'control' means possessing, directly or indirectly, the power to direct or cause the direction of the management, policies, or operations of an entity.\"),\n",
    "(\"What is the non-solicitation clause in this executive employment contract?\", \"The non-solicitation clause in this executive employment contract states that upon termination of the individual's relationship with the Company, they shall not solicit, induce, recruit, or encourage any Company employee to leave the Company, or take away such employees, or attempt to do so for themselves or for any other person or entity.\"),\n",
    "(\"What is the definition of 'Competitor' in this executive employment contract?\", \"In this executive employment contract, 'Competitor' includes but is not limited to the following entities and their wholly owned subsidiaries: Tata Consultancy Services Limited, Accenture Limited, International Business Machines Corporation, Cognizant Technology Solutions Corporation, Wipro Limited, Tech Mahindra Limited, Capgemini.\"),\n",
    "(\"What is the annual increase policy at Infosys Limited?\", \"Annual increments to components of an employee's compensation at Infosys Limited are determined on an annual basis by the Board or the Committee at its sole discretion, taking into account the Company’s prior years’ audited financial performance and independent compensation benchmarks.\"),\n",
    "(\"What is the National Pension Scheme offered by Infosys Limited?\", \"Infosys Limited offers all its India based employees the option to contribute towards the National Pension Scheme, which is an optional retirement benefit introduced by the Government of India for all its citizens. It enables accumulation of retirement corpus during active employment with add-on tax breaks.\"),\n",
    "(\"What is the consequence of a breach of confidentiality at Infosys Limited?\", \"A breach of confidentiality at Infosys Limited may result in legal action against the employee, including injunctive relief and monetary damages.\"),\n",
    "(\"What is the policy regarding taxes at Infosys Limited?\", \"All payments at Infosys Limited are subject to applicable taxes and statutory withholding.\"),\n",
    "(\"What is the policy regarding the termination of employment at Infosys Limited?\", \"The policy regarding the termination of employment at Infosys Limited is outlined in section 12 of the executive employment contract, which includes provisions for resignation, termination for cause, and termination without cause.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "dataset_name = f\"Retrieval QA Questions {str(uuid.uuid4())}\"\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "for q, a in examples:\n",
    "    client.create_example(inputs={\"question\": q}, outputs={\"answer\": a}, dataset_id=dataset.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model = \"C:/Users/arasu/Workspace/Projects/GenAI/models/MBZUAILaMini-Flan-T5-248M/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model,truncation=True)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model)\n",
    "from transformers import  pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "pipe = pipeline(\n",
    "        'text2text-generation',\n",
    "        model = base_model,\n",
    "        tokenizer = tokenizer,\n",
    "        max_length = 256,\n",
    "        do_sample = True,\n",
    "        temperature = 0.3,\n",
    "        top_p= 0.95\n",
    "    )\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"C:/Users/arasu/Workspace/Projects/GenAI/embeddings/hkunlp_instructor-large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "db_path = \"vector_db\"\n",
    "vector_db = Chroma(persist_directory=db_path,embedding_function=instructor_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "from datetime import datetime\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are friendly customer care assistant\"\n",
    "            \" trying to help user on the context provided.\"),\n",
    "            (\"system\", \"{context}\"),\n",
    "            (\"human\",\"{question}\")\n",
    "        ]\n",
    "    ).partial(time=str(datetime.now()))\n",
    "    \n",
    "response_generator = (\n",
    "    prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full chain looks like the following\n",
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    # The runnable map here routes the original inputs to a context and a question dictionary to pass to the response generator\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever | (lambda docs: \"\\n\".join([doc.page_content for doc in docs])),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | response_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The individual's role in this executive employment contract is Chief Operating Officer of Infosys Limited."
     ]
    }
   ],
   "source": [
    "for tok in chain.stream({\"question\": \"What is the role of the individual in this executive employment contract?\"}):\n",
    "    print(tok, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "eval_config = RunEvalConfig(\n",
    "    evaluators=[\"qa\"],\n",
    "    # If you want to configure the eval LLM:\n",
    "    eval_llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'damp-attitude-63' at:\n",
      "https://smith.langchain.com/o/9e5b74d3-3844-5299-8661-dcadae2c46dc/datasets/5fbc064c-48bb-402a-8d14-115a8691edfa/compare?selectedSessions=1bfcab8c-70f0-4088-9156-750e2264e454\n",
      "\n",
      "View all tests for Dataset Retrieval QA Questions 9dde8242-490b-461f-8618-37ad5bc42001 at:\n",
      "https://smith.langchain.com/o/9e5b74d3-3844-5299-8661-dcadae2c46dc/datasets/5fbc064c-48bb-402a-8d14-115a8691edfa\n",
      "[------------------------------------------------->] 13/13"
     ]
    }
   ],
   "source": [
    "_ = await client.arun_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=lambda: chain,\n",
    "    evaluation=eval_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
